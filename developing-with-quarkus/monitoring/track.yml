challenges:
- assignment: "## Login to OpenShift\n\n**Red Hat OpenShift Container Platform** is\
    \ the preferred container orchestration platform for Quarkus. OpenShift is based\
    \ on **Kubernetes** which is the most used Orchestration\nfor containers running\
    \ in production.\n\nIn order to login, we will use the **oc** command and then\
    \ specify the server that we\nwant to authenticate to:\n\n```\noc login -u developer\
    \ -p developer\n```\n\nCongratulations, you are now authenticated to the OpenShift\
    \ server.\n\n## Access OpenShift Project\n\n[Projects](https://docs.openshift.com/container-platform/3.11/architecture/core_concepts/projects_and_users.html#projects)\n\
    are a top level concept to help you organize your deployments. An\nOpenShift project\
    \ allows a community of users (or a user) to organize and manage\ntheir content\
    \ in isolation from other communities.\n\nFor this scenario, let's create a project\
    \ that you will use to house your applications. Click:\n\n```\noc new-project\
    \ quarkus --display-name=\"Sample Monitored Quarkus App\"\n```\n\n## Create Prometheus\
    \ Configuration\n\nNext, let\u2019s install Prometheus. Prometheus is an open-source\
    \ systems monitoring and alerting toolkit featuring:\n\n  - a multi-dimensional\
    \ [data model](https://prometheus.io/docs/concepts/data_model/) with time series\
    \ data identified by metric name and key/value pairs\n\n  - [PromQL](https://prometheus.io/docs/prometheus/latest/querying/basics/),\
    \ a flexible query language to leverage this dimensionality\n\n  - time series\
    \ collection happens via a pull model over HTTP\n\nTo install it, first create\
    \ a Kubernetes ConfigMap that will hold the Prometheus configuration. Click on\
    \ the following command to create this file:\n\n```\ncat <<EOF > /tmp/prometheus.yml\n\
    global:\n  scrape_interval:     15s\n  evaluation_interval: 15s\nalerting:\n \
    \ alertmanagers:\n  - static_configs:\n    - targets:\nscrape_configs:\n  - job_name:\
    \ 'prometheus'\n    static_configs:\n    - targets: ['localhost:9090']\n  - job_name:\
    \ 'hello-app'\n    metrics_path: '/q/metrics'\n    static_configs:\n    - targets:\
    \ ['primes']\nEOF\n```\n`\n```\n\nThis file contains basic Prometheus configuration,\
    \ plus a specific `scrape_config` which instructs Prometheus to\nlook for application\
    \ metrics from both Prometheus itself, and a Quarkus app called `primes` (which\
    \ we'll create later) at the `/q/metrics` endpoint.\n\nNext, click this command\
    \ to create a ConfigMap with the above file:\n\n```\noc create configmap prom\
    \ --from-file=prometheus.yml=/tmp/prometheus.yml\n```\n\n## Deploy Prometheus\n\
    \nNext, deploy and expose Prometheus using its public Quay.io image:\n\n```\n\
    oc new-app quay.io/prometheus/prometheus && oc expose svc/prometheus\n```\n\n\
    And finally, mount the ConfigMap into the running container:\n\n```\noc set volume\
    \ deployment/prometheus --add -t configmap --configmap-name=prom -m /etc/prometheus/prometheus.yml\
    \ --sub-path=prometheus.yml\n```\n\nThis will cause the contents of the ConfigMap\
    \ data to be mounted at `/etc/prometheus/prometheus.yml` inside its container\n\
    where Prometheus is expecting it.\n\nVerify Prometheus is up and running:\n\n\
    ```\noc rollout status -w deployment/prometheus\n```\n\nYou should see `deployment\
    \ \"prometheus\" successfully rolled out`.\n\n> If this command appears to hang,\
    \ just press `CTRL-C` and click it again.\n"
  difficulty: basic
  slug: 01-install-prometheus
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 1
  type: challenge
- assignment: "# Inspect Java runtime and create basic project\n\nAn appropriate Java\
    \ runtime has been installed for you. Ensure you can use it by running this command:\n\
    \n`$JAVA_HOME/bin/java --version`{{execute T1}}\n\nThe command should report the\
    \ version in use, for example (the versions and dates may be slightly different\
    \ than the below example):\n\n```console\nopenjdk 11.0.10 2021-01-19\nOpenJDK\
    \ Runtime Environment AdoptOpenJDK (build 11.0.10+9)\nOpenJDK 64-Bit Server VM\
    \ AdoptOpenJDK (build 11.0.10+9, mixed mode)\n```\n\nIf the command fails, wait\
    \ a few moments and try again (it is installed in a background process and make\
    \ take a few moments depending on system load).\n\n## Create basic project\n\n\
    Let's create the basic Quarkus _Hello World_ application and include the necessary\
    \ monitoring extensions. Click this command to create the project:\n\n`cd /root/projects/quarkus\
    \ && \\\nmvn io.quarkus:quarkus-maven-plugin:2.0.0.Final:create \\\n    -DprojectGroupId=org.acme\
    \ \\\n    -DprojectArtifactId=primes \\\n    -DclassName=\"org.acme.quickstart.GreetingResource\"\
    \ \\\n    -Dextensions=\"micrometer-registry-prometheus\" \\\n    -Dpath=\"/hello\"\
    `{{execute T1}}\n\nThis will use the Quarkus Maven Plugin and generate a basic\
    \ Maven project for you in the `primes` subdirectory and include the `micrometer-registry-prometheus`\
    \ extension which causes the app to generate metrics at the `/q/metrics` endpoint.\n\
    \n## Start the app\n\nChange to the directory in which the app was created:\n\n\
    `cd /root/projects/quarkus/primes`{{execute T1}}\n\nLet's begin Live Coding. Click\
    \ on the following command to start the app in _Live Coding_ mode:\n\n`mvn quarkus:dev`{{execute\
    \ T1}}\n\nYou should see:\n\n```console\n__  ____  __  _____   ___  __ ____  ______\n\
    \ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/\n -/ /_/ / /_/ / __ |/ , _/ ,< /\
    \ /_/ /\\ \\\n--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/\nINFO  [io.quarkus]\
    \ (Quarkus Main Thread) primes 1.0.0-SNAPSHOT on JVM (powered by Quarkus x.xx.x.Final)\
    \ started in x.xxxs. Listening on: http://localhost:8080\nINFO  [io.quarkus] (Quarkus\
    \ Main Thread) Profile dev activated. Live Coding activated.\nINFO  [io.quarkus]\
    \ (Quarkus Main Thread) Installed features: [cdi, micrometer, resteasy]\n\n--\n\
    Tests paused, press [r] to resume, [h] for more options>\n```\n\n> The first time\
    \ you build the app, new dependencies may be downloaded via maven. This should\
    \ only happen once, after that things will go even faster.\n\nNote the amazingly\
    \ fast startup time! The app is now running \"locally\" (within the Linux container\
    \ in which this exercise runs).\n\nTest that the app is running by accessing the\
    \ simple `hello` endpoint:\n\n`cd /root/projects/quarkus/primes && \\\n  curl\
    \ http://localhost:8080/hello`{{execute T2}}\n\n> You may need to click this command\
    \ again in case it doesn't execute properly on first click\n\nyou should see\n\
    \n```console\nHello RESTEasy\n```\n\n## Test Metrics endpoint\n\nYou will be able\
    \ to immediately see the raw metrics generated from Quarkus apps. Run this in\
    \ the Terminal:\n\n`curl http://localhost:8080/q/metrics`{{execute T2}}\n\nYou\
    \ will see a bunch of raw metrics in the OpenMetrics format (as we are using a\
    \ Prometheus registry):\n\n```console\n# TYPE http_server_bytes_read summary\n\
    http_server_bytes_read_count 1.0\nhttp_server_bytes_read_sum 0.0\n# HELP http_server_bytes_read_max\n\
    # TYPE http_server_bytes_read_max gauge\nhttp_server_bytes_read_max 0.0\n```\n\
    \nThis is what Prometheus will do to access and index the metrics from our app\
    \ when we deploy it to the cluster.\n\n### Using other Registry Implementations\n\
    \nIt is possible to use other systems to consume metrics other than Prometheus,\
    \ for example StackDriver (part of the [Quarkiverse](https://github.com/quarkiverse/quarkiverse-micrometer-registry)).\
    \ You can also use other pre-packaged registries for other APM systems. Consult\
    \ the [Quarkus Micrometer Guide](https://quarkus.io/guides/micrometer) for more\
    \ detail."
  difficulty: basic
  slug: 02-create-and-instrument-app
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 2
  type: challenge
- assignment: "# Add additional metrics\n\nOut of the box, you get a lot of basic\
    \ JVM metrics which are useful, but what if you wanted to provide metrics for\
    \ your\napp? Let\u2019s add a few using the Quarkus metrics APIs.\n\nClick here\
    \ to open a new file `./primes/src/main/java/org/acme/quickstart/PrimeNumberResource.java`{{open}}.\n\
    \nThis new class will implement an algorithm for checking whether a number is\
    \ a prime number. This algorithm is exposed over a REST interface. With the Micrometer\
    \ extension enabled, metrics for all http server requests are also collected automatically.\n\
    \nWe do want to add a few other metrics to demonstrate how to add and filter metrics:\n\
    \n* A counter will be incremented for every prime number discovered\n* A gauge\
    \ will store the highest prime number discovered\n* A timer will record the time\
    \ spent testing if a number is prime.\n\nClick **Copy To Editor** to create the\
    \ code for our new class:\n\n<pre class=\"file\" data-filename=\"./primes/src/main/java/org/acme/quickstart/PrimeNumberResource.java\"\
    \ data-target=\"replace\">\npackage org.acme.quickstart;\n\nimport io.micrometer.core.instrument.MeterRegistry;\n\
    \nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\n\
    import javax.ws.rs.Produces;\nimport javax.ws.rs.core.MediaType;\nimport java.util.concurrent.atomic.LongAccumulator;\n\
    import java.util.function.Supplier;\n\n@Path(&quot;/is-prime&quot;)\npublic class\
    \ PrimeNumberResource {\n\n    private final LongAccumulator highestPrime = new\
    \ LongAccumulator(Long::max, 0);\n    private final MeterRegistry registry;\n\n\
    \    PrimeNumberResource(MeterRegistry registry) {\n        this.registry = registry;\n\
    \n        // Create a gauge that uses the highestPrimeNumberSoFar method\n   \
    \     // to obtain the highest observed prime number\n        registry.gauge(&quot;prime.number.max&quot;,\
    \ this,\n                PrimeNumberResource::highestObservedPrimeNumber);\n \
    \   }\n\n    @GET\n    @Path(&quot;/{number}&quot;)\n    @Produces(MediaType.TEXT_PLAIN)\n\
    \    public String checkIfPrime(@PathParam(&quot;number&quot;) long number) {\n\
    \        if (number &lt; 1) {\n            return &quot;Only natural numbers can\
    \ be prime numbers.&quot;;\n        }\n        if (number == 1) {\n          \
    \  return &quot;1 is not prime.&quot;;\n        }\n        if (number == 2) {\n\
    \            return &quot;2 is prime.&quot;;\n        }\n        if (number %\
    \ 2 == 0) {\n            return number + &quot; is not prime, it is divisible\
    \ by 2.&quot;;\n        }\n\n        Supplier&lt;String&gt; supplier = () -&gt;\
    \ {\n            for (int i = 3; i &lt; Math.floor(Math.sqrt(number)) + 1; i =\
    \ i + 2) {\n                if (number % i == 0) {\n                    return\
    \ number + &quot; is not prime, is divisible by &quot; + i + &quot;.&quot;;\n\
    \                }\n            }\n            highestPrime.accumulate(number);\n\
    \            return number + &quot; is prime.&quot;;\n        };\n\n        return\
    \ registry.timer(&quot;prime.number.test&quot;).wrap(supplier).get();\n    }\n\
    \n    /**\n     * This method is called by the registered {@code highest.prime.number}\
    \ gauge.\n     * @return the highest observed prime value\n     */\n    long highestObservedPrimeNumber()\
    \ {\n        return highestPrime.get();\n    }\n}\n</pre>\n\nLet's test it out\
    \ by accessing the new endpoint with a few prime and non-prime numbers:\n\nClick\
    \ the following commands to test whether the number is a prime number:\n\n`curl\
    \ http://localhost:8080/is-prime/1`{{execute T2}}\n\nYou should see `1 is not\
    \ prime.`.\n\n`curl http://localhost:8080/is-prime/350`{{execute T2}}\n\nYou should\
    \ see `350 is not prime, it is divisible by 2.`.\n\n`curl http://localhost:8080/is-prime/629521085409773`{{execute\
    \ T2}}\n\nYou should see `629521085409773 is prime.`.\n\n`curl http://localhost:8080/is-prime/1111111111111111111`{{execute\
    \ T2}}\n\nYou should see `1111111111111111111 is prime.`.\n\nEach command will\
    \ output whether the number is prime or not. The last two commands will take considerably\
    \ longer (up to 5-10 seconds) as these are large prime numbers (that also form\
    \ [the basis](https://access.redhat.com/blogs/766093/posts/2177481) of modern\
    \ internet security!).\n\nReview the metrics generated so far to see them in action:\n\
    \n`curl http://localhost:8080/q/metrics`{{execute T2}}\n\nYou'll see many metrics,\
    \ for example:\n\n```\n# HELP prime_number_max\n# TYPE prime_number_max gauge\n\
    prime_number_max 887.0\n# TYPE http_server_requests_seconds summary\nhttp_server_requests_seconds_count{method=\"\
    GET\",outcome=\"SUCCESS\",status=\"200\",uri=\"/is-prime/{number}\",} 4.0\nhttp_server_requests_seconds_sum{method=\"\
    GET\",outcome=\"SUCCESS\",status=\"200\",uri=\"/is-prime/{number}\",} 0.082716484\n\
    ```\n\nYou can also display only our \"prime\"-related metrics:\n\n`curl -s http://localhost:8080/q/metrics\
    \ | grep -i prime`{{execute T2}}\n\n> **NOTE**: Metrics are generated lazily,\
    \ so you often won\u2019t see any data for your endpoint until something tries\
    \ to access it!\n\n> **NOTE**: You can optionally enable the [JSON exporter](https://quarkus.io/guides/micrometer#quarkus-micrometer_quarkus.micrometer.export.json.enabled)\
    \ to output metrics as JSON-formatted objects. One enabled, requests must pass\
    \ the `Accept: application/json` HTTP header to get JSON metrics.\n\n## Configuring\
    \ and Filtering Metrics\n\nMicrometer uses `MeterFilter` instances to customize\
    \ the metrics emitted by `MeterRegistry` instances. The Micrometer extension will\
    \ detect `MeterFilter` CDI beans and use them when initializing `MeterRegistry`\
    \ instances. These can be used to exercise greater control over how and when meters\
    \ are registered and what kinds of statistics they emit. Meter filters serve three\
    \ basic functions:\n\n* **Deny** (or accept) meters from being registered.\n*\
    \ **Transform** meter IDs (e.g. changing the name, adding or removing tags, changing\
    \ description or base units).\n* **Configure** distribution statistics for some\
    \ meter types (e.g. timers)\n\nTo create MeterFilters, you can simply declare\
    \ them using annotations in your code. Quarkus will identify and inject them into\
    \ `MeterRegistry`s as they are created, based on criteria specified in the annotations.\n\
    \nClick here to open a new file `primes/src/main/java/org/acme/quickstart/CustomConfiguration.java`{{open}}.\n\
    \nClick **Copy To Editor** to create the code for our new class:\n\n<pre class=\"\
    file\" data-filename=\"./primes/src/main/java/org/acme/quickstart/CustomConfiguration.java\"\
    \ data-target=\"replace\">\npackage org.acme.quickstart;\n\nimport java.util.Arrays;\n\
    \nimport javax.annotation.Priority;\nimport javax.inject.Singleton;\nimport javax.interceptor.Interceptor;\n\
    import javax.enterprise.inject.Produces;\n\nimport org.eclipse.microprofile.config.inject.ConfigProperty;\n\
    \nimport io.micrometer.core.instrument.Clock;\nimport io.micrometer.core.instrument.Meter;\n\
    import io.micrometer.core.instrument.Tag;\nimport io.micrometer.core.instrument.config.MeterFilter;\n\
    import io.micrometer.core.instrument.distribution.DistributionStatisticConfig;\n\
    import io.micrometer.prometheus.PrometheusConfig;\nimport io.micrometer.prometheus.PrometheusMeterRegistry;\n\
    import io.prometheus.client.CollectorRegistry;\nimport io.quarkus.micrometer.runtime.MeterFilterConstraint;\n\
    \n@Singleton\npublic class CustomConfiguration {\n\n    @ConfigProperty(name =\
    \ &quot;deployment.env&quot;)\n    String deploymentEnv;\n\n    @Produces\n  \
    \  @Singleton\n    @MeterFilterConstraint(applyTo = PrometheusMeterRegistry.class)\n\
    \    public MeterFilter configurePrometheusRegistries() {\n        return MeterFilter.commonTags(Arrays.asList(\n\
    \                Tag.of(&quot;registry&quot;, &quot;prometheus&quot;)));\n   \
    \ }\n\n    @Produces\n    @Singleton\n    public MeterFilter configureAllRegistries()\
    \ {\n        return MeterFilter.commonTags(Arrays.asList(\n                Tag.of(&quot;env&quot;,\
    \ deploymentEnv)));\n    }\n\n    /** Enable histogram buckets for a specific\
    \ timer */\n    @Produces\n    @Singleton\n    public MeterFilter enableHistogram()\
    \ {\n        return new MeterFilter() {\n            @Override\n            public\
    \ DistributionStatisticConfig configure(Meter.Id id, DistributionStatisticConfig\
    \ config) {\n                if(id.getName().startsWith(&quot;prime&quot;)) {\n\
    \                    return DistributionStatisticConfig.builder()\n          \
    \              .percentiles(0.5, 0.95)     // median and 95th percentile, not\
    \ aggregable\n                        .percentilesHistogram(true) // histogram\
    \ buckets (e.g. prometheus histogram_quantile)\n                        .build()\n\
    \                        .merge(config);\n                }\n                return\
    \ config;\n            }\n        };\n    }\n}\n</pre>\n\nThese do the following:\n\
    \n* **`configurePrometheusRegistries`** - Adds custom tag of `registry: prometheus`\
    \ to Prometheus registry metrics\n* **`configureAllRegistries`** Adds a custom\
    \ tag of `env: [value]` using the value of the `ConfigProperty` named `deploymentEnv`\
    \ (which must be present in your `application.properties`)\n* **`enableHistogram`**\
    \ - This enables any timer metric whose name begins with `prime` to report additional\
    \ quantile metrics (mean, median, and other custom histograms)\n\nFiltering and\
    \ tagging can be useful to organize the reporting, so you can more easily draw\
    \ conclusions about data.\n\nFinally, you need to add the configuration value\
    \ referenced in the `configureAllRegistries` filter to your `application.properties`.\n\
    \nClick here to open the file (it will be empty): `primes/src/main/resources/application.properties`{{open}}.\n\
    \nThen click **Copy to Editor** to add the following values to the `application.properties`\
    \ file:\n\n<pre class=\"file\" data-filename=\"./src/main/resources/application.properties\"\
    \ data-target=\"replace\">\n# Configure value for the tag we add to metrics\n\
    deployment.env=prod\n\n</pre>\n\nThis will cause a tag `env: prod` to be added\
    \ to each metric based on our above filter.\n\n## Test new metrics\n\nLet's do\
    \ a quick test and make sure they're working. Access the endpoint a couple more\
    \ times by clicking on the below commands:\n\n`curl http://localhost:8080/is-prime/350`{{execute\
    \ T2}}\n\n`curl http://localhost:8080/is-prime/629521085409773`{{execute T2}}\n\
    \nNow let's see if it worked. Let's look for our `prime` metrics with this command:\n\
    \n`curl -s http://localhost:8080/q/metrics | grep prime`{{execute T2}}\n\nYou\
    \ should see new types of quantile metrics along with our new `env` and `registry`\
    \ tags:\n\n```console\nprime_number_test_seconds{env=\"prod\",registry=\"prometheus\"\
    ,quantile=\"0.5\",} 0.0\nprime_number_test_seconds{env=\"prod\",registry=\"prometheus\"\
    ,quantile=\"0.95\",} 0.0\nprime_number_test_seconds_bucket{env=\"prod\",registry=\"\
    prometheus\",le=\"0.001\",} 0.0\nprime_number_test_seconds_bucket{env=\"prod\"\
    ,registry=\"prometheus\",le=\"0.001048576\",} 0.0\nprime_number_test_seconds_bucket{env=\"\
    prod\",registry=\"prometheus\",le=\"0.001398101\",} 0.0\nprime_number_test_seconds_bucket{env=\"\
    prod\",registry=\"prometheus\",le=\"0.001747626\",} 0.0\n...\n```\n\nIt's not\
    \ that fun to read the raw output, it'd be better if we had a better way to manage\
    \ the monitoring of these metrics. Let's do that with Prometheus and OpenShift!\n\
    \n## Cleanup\n\nWe're done coding, so let's stop the app. In the first Terminal,\
    \ press `CTRL-C` to stop the running Quarkus app (or click the `clear`{{execute\
    \ T1 interrupt}} command to do it for you).\n\n"
  difficulty: basic
  slug: 03-add-additional-metrics
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 3
  type: challenge
- assignment: "Now that we have our app built, let's move it into containers and into\
    \ the cloud where Prometheus can scrape from.\n\n## Install OpenShift extension\n\
    \nQuarkus offers the ability to automatically generate OpenShift resources based\
    \ on sane default and user supplied configuration. The OpenShift extension is\
    \ actually a wrapper extension that brings together the [kubernetes](https://quarkus.io/guides/deploying-to-kubernetes)\
    \ and [container-image-s2i](https://quarkus.io/guides/container-image#s2i) extensions\
    \ with defaults so that it\u2019s easier for the user to get started with Quarkus\
    \ on OpenShift.\n\nRun the following command to add it to our project:\n\n`mvn\
    \ quarkus:add-extension -Dextensions=\"openshift\"`{{execute T1}}\n\nOpen here\
    \ to add OpenShift properties: `primes/src/main/resources/application.properties`{{open}}.\n\
    \nThen click **Copy to Editor** to add the following values to the `application.properties`\
    \ file:\n\n<pre class=\"file\" data-filename=\"./src/main/resources/application.properties\"\
    \ data-target=\"append\">\n# Configure the OpenShift extension options\nquarkus.kubernetes-client.trust-certs=true\n\
    quarkus.container-image.build=true\nquarkus.kubernetes.deploy=true\nquarkus.kubernetes.deployment-target=openshift\n\
    quarkus.openshift.expose=true\nquarkus.openshift.labels.app.openshift.io/runtime=quarkus\n\
    \n</pre>\n\nFor more details of the above options:\n\n* `quarkus.kubernetes-client.trust-certs=true`\
    \ - We are using self-signed certs in this simple example, so this simply says\
    \ to the extension to trust them.\n* `quarkus.container-image.build=true` - Instructs\
    \ the extension to build a container image\n* `quarkus.kubernetes.deploy=true`\
    \ - Instructs the extension to deploy to OpenShift after the container image is\
    \ built\n* `quarkus.kubernetes.deployment-target=openshift` - Instructs the extension\
    \ to generate and create the OpenShift resources (like `DeploymentConfig`s and\
    \ `Service`s) after building the container\n* `quarkus.openshift.route.expose=true`\
    \ - Instructs the extension to generate an OpenShift `Route`.\n* `quarkus.openshift.labels.app.openshift.io/runtime=quarkus`\
    \ - Adds a nice-looking icon to the app when viewing the OpenShift Developer Toplogy\n\
    \n## Deploy to OpenShift\n\nNow let's deploy the application itself. Run the following\
    \ command which will build and deploy using the OpenShift extension (it will take\
    \ a minute or two):\n\n`mvn clean package -DskipTests`{{execute T1}}\n\n> **NOTE**:\
    \ This command will take a minute or two, as it builds the app, pushes a container\
    \ image, and finally deploys the container to OpenShift.\n\nThe output should\
    \ end with `BUILD SUCCESS`.\n\nFinally, make sure it's actually done rolling out:\n\
    \n`oc rollout status -w dc/primes`{{execute T1}}\n\nWait for that command to report\
    \ `replication controller \"primes-1\" successfully rolled out` before continuing.\n\
    \nYou can also see the app deployed in the [OpenShift Developer Toplogy](https://console-openshift-console-[[HOST_SUBDOMAIN]]-443-[[KATACODA_HOST]].environments.katacoda.com/topology/ns/quarkus):\n\
    \nYou'll need to login with the same credentials as before:\n\n* Username: `developer`\n\
    * Password: `developer`\n\n![Deployed App](/openshift/assets/middleware/quarkus/primedep.png)\n\
    \nAnd now we can access using `curl` once again to test our prime service running\
    \ on OpenShift. Click the commands to access the app on OpenShift:\n\n```\ncurl\
    \ http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/1\n\
    ```\n\n```\ncurl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/350\n\
    ```\n\n`curl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/629521085409773`{{execute\
    \ T1}}\n\nWith our app rolled out, Prometheus should start collecting metrics.\
    \ Let's take a look in the next exercise."
  difficulty: basic
  slug: 04-deploy-to-openshift
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 4
  type: challenge
- assignment: "## Generate Load\n\nWe will use the open source [OpenSSL](https://www.openssl.org/)\
    \ project to generate some test primes to exercise our app. Click the following\
    \ command to verify openssl is installed. If it is not, you may need to wait a\
    \ few seconds and click the command again until it reports a proper version\n\n\
    `openssl version`{{execute T1}}\n\nThen you should see\n\n```console\nOpenSSL\
    \ 1.1.1g FIPS  21 Apr 2020\n```\n\nWith our app deployed to OpenShift, let's setup\
    \ a loop that will test random numbers for primeness. Click the following command\
    \ to endlessly run `curl` every 2 seconds with a random prime number:\n\n`while\
    \ [ true ] ; do\n        BITS=$(( ( RANDOM % 60 )  + 1 ))\n        NUM=$(openssl\
    \ prime -generate -bits $BITS)\n        curl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/${NUM}\n\
    \        sleep 2\ndone`{{execute T1}}\n\nWith that running, click on this link\
    \ to [open up the Prometheus dashboard](http://prometheus-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/).\
    \ You'll see the Prometheus UI:\n\n![Prometheus UI](/openshift/assets/middleware/quarkus/prom.png)\n\
    \nWithin about 15-30 seconds, Prometheus should start scraping the metrics. Start\
    \ typing in the query box to look for `prime`:\n\n> **Note**\n>\n> If you do not\
    \ see any `prime` metrics when querying, wait 15 seconds, reload the Prometheus\
    \ page, and try again. They\n> will eventually show up\\!\n\n![Prometheus UI](/openshift/assets/middleware/quarkus/promnames.png)\n\
    \nType `prime` in the query, and select `prime_number_max` in the box, and click\
    \ **Execute**. This will\nfetch the values from our metric showing the largest\
    \ prime number found so far:\n\n![Prometheus UI](/openshift/assets/middleware/quarkus/promchecks.png)\n\
    \nCool\\! You can try this with some of the standard HTTP metrics as well, e.g.\
    \ try to graph the `http_server_requests_seconds_count` to\nsee how often our\
    \ various HTTP endpoints are accessed. You can see the endpoints shown with different\
    \ colors, one for each endpoint (`/is-prime/{number}`, `/q/metrics`, and the 404\
    \ not-found endpoint).\n\n![Prometheus UI](/openshift/assets/middleware/quarkus/promgraph.png)\n\
    \n\nKeep the `curl` loop running and we'll move on to build a full dashboard for\
    \ our app in the next step."
  difficulty: basic
  slug: 05-query-with-prometheus
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 4
  type: challenge
- assignment: "# Install Grafana\n\nWe'll keep our prime number checker running. Click\
    \ to run the following command in the other Terminal to deploy Grafana to our\
    \ cluster:\n\n`oc new-app quay.io/bitnami/grafana && oc expose svc/grafana`{{execute\
    \ T2}}\n\n> It may take up to a minute to finish deploying\n\nVerify Grafana is\
    \ up and running:\n\n```\noc rollout status -w deployment/grafana\n```\n\nYou\
    \ should see `replication controller \"grafana-1\" successfully rolled out`\n\n\
    # Open Grafana Dashboard\n\nClick on this link to [open the Grafana Dashboard\
    \ in your browser](http://grafana-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/),\
    \ and login using the default credentails:\n\n  - Username: `admin`\n  - Password:\
    \ `admin`\n\n![Grafana UI](/openshift/assets/middleware/quarkus/graflogin.png)\n\
    \nAt the password change prompt, use any password you wish.\n\n# Add Prometheus\
    \ as a data source\n\nYou\u2019ll land on the Data Source screen. Click **Add\
    \ your first data source**, and click **Select** next to **Prometheus** as the\
    \ *Data Source Type*.\n\nIn the URL box, type ``http://prometheus:9090`` (this\
    \ is the hostname and port of our running Prometheus in our\nnamespace):\n\n>\
    \ **WARNING**\n>\n> If you skip this step, you'll get errors and things won't\
    \ work! Make sure to change it to ``http://prometheus:9090``!\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafds.png)\n\
    \nClick **Save and Test**. You should see:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafworking.png)\n\
    \nWith our data source working, let\u2019s make a dashboard.\n\n"
  difficulty: basic
  slug: 06-install-grafana
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 5
  type: challenge
- assignment: "# Create Dashboard\n\nIn the Grafana Dashboard, hover over the `+`\
    \ button on the left, and select *Create \\> Dashboard*:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafcreate.png)\n\
    \nNext, click **Add an Empty Panel**.\n\nThis will create a new dashboard with\
    \ a single Panel. Each Panel can visualize a computed metric (either a single\n\
    metric, or a more complex query) and display the results in the Panel.\n\nIn the\
    \ _Metrics_ box, type `prime` to again get an autocompleted list of available\
    \ metrics that match that name:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafquery.png)\n\
    \nChoose from the drop-down `prime_number_test_seconds_max`. Then click on the\
    \ **Refresh** button to begin to show in the graph above:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafgraf.png)\n\
    \nThis is querying the custom `prime.number.test` metric from our earlier Java\
    \ code we created. With the `seconds_max` suffix it will show the max # of seconds\
    \ taken to calculate a prime from our `curl` loop still running.\n\n> **Note**:\
    \ Statistics like max, percentiles, and histogram counts decay over time to give\
    \ greater weight to recent samples, so you'll see even the `max` value going up\
    \ and down as older values drop out of the rolling window of samples.\n\nNext\
    \ click on the *Visualization* section on the right:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafvis.png)\n\
    \nThis lets you fine tune the display, along with the type of graph (bar, line,\
    \ gauge, etc). Leave them for now, and look up in the _Settings_ section above,\
    \ and change the name of the panel to `Prime Time`.\n\n![Grafana UI](/openshift/assets/middleware/quarkus/graftitle.png)\n\
    \nThere is an *Alerts* tab you can configure to send alerts (email, etc) when\
    \ conditions are met for this and other\nqueries. We\u2019ll skip this for now.\n\
    \nClick *Save* at the top right to save our new dashboard and give it a name such\
    \ as _My Prime Dashboard_.\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafsave.png)\n\
    \n# Add more Panels\n\nSee if you can add additional Panels. Use the **Add Panel**\
    \ button to add a new Panel:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafmorepanels.png)\n\
    \nFollow the same steps as before to create a few more panels, and **don\u2019\
    t forget to Save each panel when you\u2019ve created\nit.**\n\nAdd Panels for:\n\
    \n  - The HTTP endpoint timers `http_server_requests_seconds_count` (name it \"\
    Primes HTTP Timer\" on the *General* tab).\n  - The RSS Memory used by the app\
    \ `process_resident_memory_bytes` (set the title to `RSS Memory` on the *General*\
    \ tab.\n\nTo see the quantile metrics, create another panel for the `prime_number_test_seconds_bucket`\
    \ metric. When you select that metric in Grafana, it will notice you'll want a\
    \ histogram panel, so click the helpful tip to show the 95% quantile:\n\n![Grafana\
    \ UI](/openshift/assets/middleware/quarkus/grafhist.png)\n\nThe graph will update\
    \ to show the 95% quantile of the time it takes to evaluate whether a number is\
    \ prime or not:\n\n![Grafana UI](/openshift/assets/middleware/quarkus/grafhistdata.png)\n\
    \n# Fix layout\n\nAfter saving, go back to the main dashboard (click on **Quar**\
    \ at the top and then select it under *Recent\nDashboards*). Change the time value\
    \ to *Last 15 Minutes* at the top-right:\n\n![time](/openshift/assets/middleware/quarkus/graftime.png)\n\
    \nFinally, drag and resize the different panels to look nice and fit on a single\
    \ page.\n\nClick **Save Dashboad** again to save it. Your final Dashboard should\
    \ look like:\n\n![final](/openshift/assets/middleware/quarkus/graffinal.png)\n\
    \nYou can add many more metrics to monitor and alert for Quarkus apps using these\
    \ tools.\n\n# Open the solution in an IDE in the Cloud!\nWant to continue exploring\
    \ this solution on your own in the cloud? You can use the free [Red Hat CodeReady\
    \ Workspaces](https://developers.redhat.com/products/codeready-workspaces/overview)\
    \ IDE running on the free [Red Hat Developer Sandbox](http://red.ht/dev-sandbox).\
    \ [Click here](https://workspaces.openshift.com) to login or to register if you\
    \ are a new user. This free service expires after 30 days, but you can always\
    \ enable a new free 30-day subscription.\n\nOnce logged in, [click here](https://workspaces.openshift.com/f?url=https://raw.githubusercontent.com/openshift-katacoda/rhoar-getting-started/solution/quarkus/monitoring/devfile.yaml)\
    \ to open the solution for this project in the cloud IDE. While loading, if it\
    \ asks you to update or install any plugins, you can say no.\n\n# Fork the source\
    \ code to your own GitHub!\nWant to experiment more with the solution code you\
    \ just worked with? If so, you can fork the repository containing the solution\
    \ to your own GitHub repository by clicking on the following command to execute\
    \ it:\n\n`/root/projects/forkrepo.sh`{{execute T1}}\n- Make sure to follow the\
    \ prompts. An error saying `Failed opening a web browser at https://github.com/login/device\
    \ exit status 127` is expected.\n- [Click here](https://github.com/login/device)\
    \ to open a new browser tab to GitHub and paste in the code you were presented\
    \ with and you copied.\n- Once done with the GitHub authorization in the browser,\
    \ close the browser tab and return to the console and press `Enter` to complete\
    \ the authentication process.\n- If asked to clone the fork, press `n` and then\
    \ `Enter`.\n- If asked to confirm logout, press `y` and the `Enter`.\n\n   > **NOTE:**\
    \ This process uses the [GitHub CLI](https://cli.github.com) to authenticate with\
    \ GitHub. The learn.openshift.com site is not requesting nor will have access\
    \ to your GitHub credentials.\n\nAfter completing these steps the `rhoar-getting-started`\
    \ repo will be forked in your own GitHub account. On the `solution` branch in\
    \ the repo, the `monitoring` project inside the `quarkus` folder contains the\
    \ completed solution for this scenario.\n\n# Congratulations\\!\n\nThis exercise\
    \ demonstrates how your Quarkus application can utilize the [Micrometer\nMetrics\
    \ extension](https://quarkus.io/guides/micrometer) to visualize metrics for Quarkus\
    \ applications. You also\nconsumed these metrics using a popular monitoring stack\
    \ with Prometheus and Grafana and other APM tools that support Micrometer.\n\n\
    There are many more possibilities for application metrics, and it\u2019s a useful\
    \ way to not only gather metrics, but act on\nthem through alerting and other\
    \ features of the monitoring stack you may be using.\n"
  difficulty: basic
  slug: 07-create-dashboard
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: 30443
    title: web-ui
    type: service
  timelimit: 300
  title: Step 6
  type: challenge
description: 'This exercise demonstrates how your Quarkus application can utilize
  the [Micrometer Metrics](https://quarkus.io/guides/micrometer) extension to produce
  and observe metrics generated by the application.


  [Micrometer](https://micrometer.io/) allows applications to gather various metrics
  and statistics that provide insights into what is happening inside the application.
  They serve to pinpoint issues, provide long term trend data for capacity planning
  and pro-active discovery of issues (e.g. disk usage growing without bounds). Metrics
  can also help those scheduling systems decide when to scale the application to run
  on more or fewer machines.


  Micrometer defines a core library and a set of additional libraries that support
  different monitoring systems. Quarkus Micrometer extensions are structured similarly:
  quarkus-micrometer provides core micrometer support and runtime integration and
  other supporting Quarkus and Quarkiverse extensions bring in additional dependencies
  and requirements to support specific monitoring systems.


  ### Other possibilities


  Learn more at [quarkus.io](https://quarkus.io), or just drive on and get hands-on!'
developers:
- btannous@redhat.com
- nvinto@redhat.com
- rjarvine@redhat.com
icon: https://logodix.com/logo/1910931.png
level: beginner
owner: openshift
private: true
published: false
skipping_enabled: false
slug: monitoring
tags:
- openshift
title: Monitoring Quarkus with Micrometer
type: track
