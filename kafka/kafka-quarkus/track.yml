challenges:
- assignment: "You start this scenario with a basic Maven-based application, which\
    \ is created using the Quarkus maven plugin.\n\n### Add an extension to integrate\
    \ with Kafka\n\nThe current project needs the extensions to be added to integrate\
    \ Quarkus with Apache Kafka.\n\nChange to the project folder:\n\n```\ncd /opt/projects/kafka-quarkus`\n\
    ```\n\nInstall the extension into the project with the following command:\n\n\
    ```\nmvn quarkus:add-extension -Dextension=\"quarkus-smallrye-reactive-messaging-kafka\"\
    `\n```\n\n>The first time you add the extension will take longer, as Maven downloads\
    \ new dependencies.\n\nThis will add the necessary entries in your `pom.xml`{{open}}\
    \ to bring in the Kafka extension. You should see a fragment similar to this around\
    \ line 50:\n\n```xml\n...\n<dependency>\n    <groupId>io.quarkus</groupId>\n \
    \   <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n</dependency>\n\
    ...\n```\n\n### Configure a channel to integrate with the event broker\n\nNext,\
    \ we need to configure the application to define how are we going to connect to\
    \ the event broker.\n\nThe MicroProfile Reactive Messaging properties are structured\
    \ as follows:\n\n```properties\nmp.messaging.[outgoing|incoming].{channel-name}.property=value\n\
    ```\n\nThe `channel-name` segment must match the value set in the `@Incoming`\
    \ and `@Outgoing` annotations. To indicate that a channel is managed by the Kafka\
    \ connector we need:\n\n```properties\nmp.messaging.[outgoing|incoming].{channel-name}.connector=smallrye-kafka\n\
    ```\n\nOpen the `src/main/resources/application.properties`{{open}} file to add\
    \ the following configuration:\n\n<pre class=\"file\" data-filename=\"./src/main/resources/application.properties\"\
    \ data-target=\"replace\">\n# Configuration file\nkafka.bootstrap.servers=my-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092\n\
    \nmp.messaging.outgoing.uber.connector=smallrye-kafka\nmp.messaging.outgoing.uber.key.serializer=org.apache.kafka.common.serialization.StringSerializer\n\
    mp.messaging.outgoing.uber.value.serializer=org.apache.kafka.common.serialization.StringSerializer\n\
    </pre>\n\n> You can click **Copy to Editor** to add the values into the file\n\
    \nYou can see we added the kafka bootstrap server hostname and port for the broker\
    \ locations and the configuration for a channel named `uber`. The `key` and `value`\
    \ serializers are part of the  [Producer configuration](https://kafka.apache.org/documentation/#producerconfigs)\
    \ and [Consumer configuration](https://kafka.apache.org/documentation/#consumerconfigs)\
    \ to encode the message payload.\n\n>You don\u2019t need to set the Kafka topic.\
    \ By default, it uses the channel name (`uber`). You can, however, configure the\
    \ topic attribute to override it.\n"
  difficulty: intermediate
  slug: step1
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: '30443'
    title: web-ui
    type: service
  timelimit: '300'
  title: Adding a Quarkus Reactive Messaging Extension
  type: challenge
- assignment: "This project has already a `VehicleGenerator` class that will be used\
    \ to send events to Kafka. However, it is missing the Reactive Messaging code.\n\
    \n### Writing Kafka Records\n\nThe Kafka connector can write Reactive Messaging\
    \ messages as Kafka records.\n\nOpen the `src/main/java/com/redhat/katacoda/kafka/VehicleGenerator.java`{{open}}\
    \ file to check the code.\n\nWe will be sending the events to the `uber` channel\
    \ by adding the following method:\n\n<pre class=\"file\" data-filename=\"./src/main/java/com/redhat/katacoda/kafka/VehicleGenerator.java\"\
    \ data-target=\"insert\" data-marker=\"//  TODO-publisher\">\n    @Outgoing(\"\
    uber\")\n    public Flowable&lt;KafkaRecord&lt;String, String&gt;&gt; generateUber()\n\
    \    {\n        return Flowable.interval(5000, TimeUnit.MILLISECONDS)\n      \
    \          .map(tick -> {\n                    VehicleInfo vehicle = randomVehicle(\"\
    uber\");\n                    LOG.info(\"dispatching vehicle: {}\", vehicle);\n\
    \                    return KafkaRecord.of(String.valueOf(vehicle.getVehicleId()),\
    \ Json.encodePrettily(vehicle));\n                });\n    }\n</pre>\n\n> You\
    \ can click in **Copy to Editor** to add the values into the file\n\nThis simple\
    \ method:\n\n- Instructs Reactive Messaging to dispatch the items from returned\
    \ stream to the `uber`channel.\n- Returns an [RX Java 2 stream](https://github.com/ReactiveX/RxJava)\
    \ (`Flowable`) emitting random vehicle information every 5 seconds\n"
  difficulty: intermediate
  slug: step2
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: '30443'
    title: web-ui
    type: service
  timelimit: '300'
  title: Creating an event generator
  type: challenge
- assignment: "With Quarkus, you can automatically generate OpenShift resources from\
    \ default and user-supplied configuration. The OpenShift extension is a wrapper\
    \ extension that brings together the [kubernetes](https://quarkus.io/guides/deploying-to-kubernetes)\
    \ and [container-image-s2i](https://quarkus.io/guides/container-image#s2i) extensions\
    \ with useful defaults so that it\u2019s easier to get started with Quarkus on\
    \ OpenShift.\n\nRun the following command to add the extension to the project:\n\
    \n```\nmvn quarkus:add-extension -Dextensions=\"openshift\"\n```\n\nReopen the\
    \ `src/main/resources/application.properties`{{open}} file and click **Copy to\
    \ Editor** to add the following values:\n\n<pre class=\"file\" data-filename=\"\
    ./src/main/resources/application.properties\" data-target=\"append\">\n# Configures\
    \ the OpenShift extension options\nquarkus.kubernetes-client.trust-certs=true\n\
    quarkus.container-image.build=true\nquarkus.kubernetes.deploy=true\nquarkus.kubernetes.deployment-target=openshift\n\
    quarkus.openshift.labels.app.openshift.io/runtime=quarkus\nquarkus.s2i.base-jvm-image=registry.access.redhat.com/ubi8/openjdk-8\n\
    </pre>\n\nHere's a summary of of the properties added:\n\n* `quarkus.kubernetes-client.trust-certs=true`\
    \ - We are using self-signed certificates in this example, so this simply says\
    \ to the extension to trust them.\n* `quarkus.container-image.build=true` - Instructs\
    \ the extension to build a container image.\n* `quarkus.kubernetes.deploy=true`\
    \ - Instructs the extension to deploy to OpenShift after the container image is\
    \ built.\n* `quarkus.kubernetes.deployment-target=openshift` - Instructs the extension\
    \ to generate and create the OpenShift resources (like `DeploymentConfig`s and\
    \ `Service`s) after building the container.\n* `quarkus.openshift.expose=true`\
    \ - Instructs the extension to generate an OpenShift `Route`.\n* `quarkus.openshift.labels.app.openshift.io/runtime=java`\
    \ - Adds an icon for the application when viewing the application from the Topology\
    \ view of the OpenShift Developer perspective.\n\n### Login to OpenShift\n\nWe'll\
    \ deploy the application as the `developer` user. Run the following command to\
    \ login with the OpenShift `oc` CLI tool:\n\n```\noc login -u developer -p developer\n\
    ```\n\nYou should see\n\n```sh\nLogin successful.\n\nYou have one project on this\
    \ server: \"kafka\"\n\nUsing project \"kafka\".\n```\n\n### Deploy the application\
    \ to OpenShift\n\nNow let's deploy the application itself. Run the following command\
    \ which will build and deploy the application using the OpenShift extension:\n\
    \n```\nmvn clean package\n```\n\nAt the end you should see an output similar to\
    \ the folllowing:\n\n```sh\n...\n[INFO] [io.quarkus.container.image.openshift.deployment.OpenshiftProcessor]\
    \ Push successful\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ Deploying to openshift server: https://openshift:6443/ in namespace: kafka.\n\
    [INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Applied: Service\
    \ kafka-quarkus.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ Applied: ImageStream kafka-quarkus.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ Applied: ImageStream openjdk-11.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ Applied: BuildConfig kafka-quarkus.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ Applied: DeploymentConfig kafka-quarkus.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ Applied: Route kafka-quarkus.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer]\
    \ The deployed application can be accessed at: http://kafka-quarkus-kafka.2886795273-80-host19nc.environments.katacoda.com\n\
    [INFO] [io.quarkus.deployment.QuarkusAugmentor] Quarkus augmentation completed\
    \ in 87529ms\n[INFO] ------------------------------------------------------------------------\n\
    [INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n\
    ```\n\n>The process will take a few moments to complete.\n\nWe are now ready to\
    \ check the Kafka records.\n"
  difficulty: intermediate
  slug: step3
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: '30443'
    title: web-ui
    type: service
  timelimit: '300'
  title: Deploying the application to OpenShift
  type: challenge
- assignment: "The application will now generate a new event with vehicle information\
    \ every 5 seconds.\n\n### Wait for the application deployment\n\nThe deployment\
    \ will start the application pods. You can monitor the pods with the following\
    \ command:\n\n```\noc get pods -l deploymentconfig=kafka-quarkus -w`\n```\n\n\
    You will see the pod changing the status to `running`:\n\n```sh\nNAME        \
    \            READY   STATUS    RESTARTS   AGE\nkafka-quarkus-1-mg8cv   0/1   \
    \  Pending   0          0s\nkafka-quarkus-1-mg8cv   0/1     Pending   0      \
    \    0s\nkafka-quarkus-1-mg8cv   0/1     ContainerCreating   0          0s\nkafka-quarkus-1-mg8cv\
    \   0/1     ContainerCreating   0          2s\nkafka-quarkus-1-mg8cv   0/1   \
    \  ContainerCreating   0          8s\nkafka-quarkus-1-mg8cv   1/1     Running\
    \             0          13s\n```\n\nPress <kbd>Ctrl</kbd>+<kbd>C</kbd> to stop\
    \ the process.\n\n`^C`{{execute ctrl-seq}}\n\n# Check the application log\n\n\
    To verify there was no problem with the application, we can check the logs with\
    \ the following command:\n\n``oc logs dc/kafka-quarkus -f``{{execute interrupt}}\n\
    \nYou should see the information of the Quarkus application connecting to Kafka\
    \ as well as the output of the sent events:\n\n```sh\n...\nINFO [io.quarkus] (main)\
    \ kafka-quarkus 1.0.0 on JVM (powered by Quarkus 1.10.3.Final) started in 2.394s.\
    \ Listening on: http://0.0.0.0:8080\nINFO [io.quarkus] (main) Profile prod activated.\n\
    INFO [io.quarkus] (main) Installed features: [cdi, kubernetes, mutiny, smallrye-context-propagation,\
    \ smallrye-reactive-messaging, smallrye-reactive-messaging-kafka, vertx]\nINFO\
    \ [com.red.kat.kaf.VehicleGenerator] (RxComputationThreadPool-1) dispatching vehicle:\
    \ VehicleInfo{provider='uber', vehicleId=1, pricePerMinute=9.633610913249816,\
    \ timeToPickup=4, availableSpace=2, available=true}\nWARN [org.apa.kaf.cli.NetworkClient]\
    \ (kafka-producer-network-thread | kafka-producer-uber) [Producer clientId=kafka-producer-uber]\
    \ Error while fetching metadata with correlation id 3 : {uber=LEADER_NOT_AVAILABLE}\n\
    WARN [org.apa.kaf.cli.NetworkClient] (kafka-producer-network-thread | kafka-producer-uber)\
    \ [Producer clientId=kafka-producer-uber] Error while fetching metadata with correlation\
    \ id 4 : {uber=LEADER_NOT_AVAILABLE}\nWARN [org.apa.kaf.cli.NetworkClient] (kafka-producer-network-thread\
    \ | kafka-producer-uber) [Producer clientId=kafka-producer-uber] Error while fetching\
    \ metadata with correlation id 5 : {uber=LEADER_NOT_AVAILABLE}\nINFO [com.red.kat.kaf.VehicleGenerator]\
    \ (RxComputationThreadPool-1) dispatching vehicle: VehicleInfo{provider='uber',\
    \ vehicleId=2, pricePerMinute=4.502112907514153, timeToPickup=15, availableSpace=5,\
    \ available=true}\n```\n\nThen you will see new events every few seconds.\n\n\
    Press <kbd>Ctrl</kbd>+<kbd>C</kbd> to stop the process.\n\n`^C`{{execute ctrl-seq}}\n\
    \n### Check the Kafka records\n\nNow, let see how the messages look within Kafka.\n\
    \nCheck the messages with this command:\n\n``oc exec -c kafka my-cluster-kafka-0\
    \ -- /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092\
    \ --topic uber --from-beginning | jq``{{execute interrupt}}\n\nThe output presents\
    \ like this:\n\n```json\n...\n{\n  \"vehicleId\": 93,\n  \"pricePerMinute\": 9.57522356183256,\n\
    \  \"timeToPickup\": 15,\n  \"availableSpace\": 3,\n  \"available\": true\n}\n\
    {\n  \"vehicleId\": 94,\n  \"pricePerMinute\": 7.255313141956367,\n  \"timeToPickup\"\
    : 21,\n  \"availableSpace\": 8,\n  \"available\": true\n}\n```\n\nPress <kbd>Ctrl</kbd>+<kbd>C</kbd>\
    \ to stop the process.\n\n`^C`{{execute ctrl-seq}}\n\nCongratulations! You are\
    \ now sending events to Kafka using the Quarkus Reactive Messaging extension for\
    \ Kafka.\n"
  difficulty: intermediate
  slug: step4
  tabs:
  - hostname: crc-nonest-1
    title: cli
    type: terminal
  - hostname: crc-nonest-1
    port: '30443'
    title: web-ui
    type: service
  timelimit: '300'
  title: Checking Kafka records
  type: challenge
developers:
- btannous@redhat.com
- nvinto@redhat.com
- rjarvine@redhat.com
icon: https://logodix.com/logo/1910931.png
level: beginner
owner:
- openshift
private: 'false'
published: 'true'
skipping_enabled: 'true'
slug: kafka-quarkus
tags:
- openshift
title: Apache Kafka with Reactive Messaging
type: truck
